{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Jupyter file will guide you to go through an interesting experiment -- using GNN to achieve a BIM node classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "# torch and dgl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from dgl.data.utils import load_graphs\n",
    "# basic machine learning libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "# self construct functions\n",
    "from node_evaluation import collate, evalEdge \n",
    "from SAGEE import SAGEE\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "device = torch.device('cpu') # CPU is enough for processing small graphs\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set basic parameters. The default runing epoch is 200. You can play with different hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 1\n",
    "n_classes = 9 # nine room classes here\n",
    "weight_decay=5e-4\n",
    "num_channels = 50\n",
    "lr = 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load RoomGraph dataset.\n",
    "\n",
    "RoomGraph is a self-designed graph dataset containing 224 apartment layouts collecting from 3 countries. \n",
    "\n",
    "RoomGraph has 9 different node classes, and each node and edge owns its feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset 161, val dataset 18, test dataset 45\n"
     ]
    }
   ],
   "source": [
    "bg = load_graphs(\"./../dataset/roomgraph.bin\")[0]\n",
    "\n",
    "# data split\n",
    "trainvalid, test_dataset =  train_test_split(bg, test_size=0.2, random_state=42)\n",
    "train_dataset, valid_dataset = train_test_split(trainvalid, test_size=0.1, random_state=42)\n",
    "\n",
    "# data batch for parallel computation\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=collate)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate)\n",
    "\n",
    "print(\"train dataset %i, val dataset %i, test dataset %i\"%(len(train_dataset), \\\n",
    "    len(valid_dataset), len(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SAGE-E model. \n",
    "\n",
    "SAGE-E is an improved algorithm based on [GraphSAGE](https://cs.stanford.edu/people/jure/pubs/graphsage-nips17.pdf). \n",
    "\n",
    "The main improvement is that SAGE-E can leverage both node and edge features, but GraphSAGE can only learn from node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAGEE(\n",
      "  (layers): ModuleList(\n",
      "    (0): SAGEELayer(\n",
      "      (W_msg): Linear(in_features=13, out_features=50, bias=True)\n",
      "      (W_apply): Linear(in_features=58, out_features=50, bias=True)\n",
      "    )\n",
      "    (1): SAGEELayer(\n",
      "      (W_msg): Linear(in_features=55, out_features=50, bias=True)\n",
      "      (W_apply): Linear(in_features=100, out_features=50, bias=True)\n",
      "    )\n",
      "    (2): SAGEELayer(\n",
      "      (W_msg): Linear(in_features=55, out_features=25, bias=True)\n",
      "      (W_apply): Linear(in_features=75, out_features=25, bias=True)\n",
      "    )\n",
      "    (3): SAGEELayer(\n",
      "      (W_msg): Linear(in_features=30, out_features=9, bias=True)\n",
      "      (W_apply): Linear(in_features=34, out_features=9, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model loading \n",
    "ndim_in = train_dataset[0].ndata['feat'].shape[1]\n",
    "edim_in = train_dataset[0].edata['relation'].shape[1]\n",
    "\n",
    "model = SAGEE(ndim_in, n_classes, edim_in,  F.relu, 0.2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 train | Accuracy: 0.4039 | Loss: 1.7499\n",
      "Validation | Accuracy: 0.5497 | Loss: 1.3826\n",
      "\n",
      "Epoch 002 train | Accuracy: 0.5778 | Loss: 1.3388\n",
      "Validation | Accuracy: 0.6221 | Loss: 1.1034\n",
      "\n",
      "Epoch 003 train | Accuracy: 0.6177 | Loss: 1.1886\n",
      "Validation | Accuracy: 0.6360 | Loss: 1.0711\n",
      "\n",
      "Epoch 004 train | Accuracy: 0.6358 | Loss: 1.1446\n",
      "Validation | Accuracy: 0.6771 | Loss: 1.0413\n",
      "\n",
      "Epoch 005 train | Accuracy: 0.6460 | Loss: 1.1100\n",
      "Validation | Accuracy: 0.6735 | Loss: 0.9827\n",
      "\n",
      "Epoch 006 train | Accuracy: 0.6518 | Loss: 1.0823\n",
      "Validation | Accuracy: 0.6702 | Loss: 1.0088\n",
      "\n",
      "Epoch 007 train | Accuracy: 0.6687 | Loss: 1.0631\n",
      "Validation | Accuracy: 0.6760 | Loss: 0.9831\n",
      "\n",
      "Epoch 008 train | Accuracy: 0.6642 | Loss: 1.0593\n",
      "Validation | Accuracy: 0.6752 | Loss: 0.9513\n",
      "\n",
      "Epoch 009 train | Accuracy: 0.6661 | Loss: 1.0547\n",
      "Validation | Accuracy: 0.6895 | Loss: 1.0017\n",
      "\n",
      "Epoch 010 train | Accuracy: 0.6777 | Loss: 1.0341\n",
      "Validation | Accuracy: 0.7218 | Loss: 0.9489\n",
      "\n",
      "Epoch 011 train | Accuracy: 0.6890 | Loss: 1.0184\n",
      "Validation | Accuracy: 0.7151 | Loss: 0.9500\n",
      "\n",
      "Epoch 012 train | Accuracy: 0.6921 | Loss: 1.0214\n",
      "Validation | Accuracy: 0.7520 | Loss: 0.9073\n",
      "\n",
      "Epoch 013 train | Accuracy: 0.6959 | Loss: 0.9990\n",
      "Validation | Accuracy: 0.7409 | Loss: 0.9369\n",
      "\n",
      "Epoch 014 train | Accuracy: 0.6753 | Loss: 1.0616\n",
      "Validation | Accuracy: 0.6455 | Loss: 0.9496\n",
      "\n",
      "Epoch 015 train | Accuracy: 0.6859 | Loss: 1.0245\n",
      "Validation | Accuracy: 0.7131 | Loss: 0.9297\n",
      "\n",
      "Epoch 016 train | Accuracy: 0.6930 | Loss: 1.0108\n",
      "Validation | Accuracy: 0.7383 | Loss: 0.9324\n",
      "\n",
      "Epoch 017 train | Accuracy: 0.7005 | Loss: 0.9985\n",
      "Validation | Accuracy: 0.7311 | Loss: 0.9217\n",
      "\n",
      "Epoch 018 train | Accuracy: 0.6987 | Loss: 0.9914\n",
      "Validation | Accuracy: 0.7519 | Loss: 0.8948\n",
      "\n",
      "Epoch 019 train | Accuracy: 0.7015 | Loss: 0.9987\n",
      "Validation | Accuracy: 0.7505 | Loss: 0.9097\n",
      "\n",
      "Epoch 020 train | Accuracy: 0.7065 | Loss: 0.9771\n",
      "Validation | Accuracy: 0.7575 | Loss: 0.8802\n",
      "\n",
      "Epoch 021 train | Accuracy: 0.7088 | Loss: 0.9836\n",
      "Validation | Accuracy: 0.7418 | Loss: 0.9158\n",
      "\n",
      "Epoch 022 train | Accuracy: 0.7011 | Loss: 0.9723\n",
      "Validation | Accuracy: 0.7621 | Loss: 0.8961\n",
      "\n",
      "Epoch 023 train | Accuracy: 0.6977 | Loss: 0.9833\n",
      "Validation | Accuracy: 0.7637 | Loss: 0.9080\n",
      "\n",
      "Epoch 024 train | Accuracy: 0.6968 | Loss: 0.9729\n",
      "Validation | Accuracy: 0.7411 | Loss: 0.8937\n",
      "\n",
      "Epoch 025 train | Accuracy: 0.7072 | Loss: 0.9664\n",
      "Validation | Accuracy: 0.7560 | Loss: 0.8586\n",
      "\n",
      "Epoch 026 train | Accuracy: 0.7155 | Loss: 0.9682\n",
      "Validation | Accuracy: 0.7621 | Loss: 0.8831\n",
      "\n",
      "Epoch 027 train | Accuracy: 0.7095 | Loss: 0.9727\n",
      "Validation | Accuracy: 0.7632 | Loss: 0.8840\n",
      "\n",
      "Epoch 028 train | Accuracy: 0.7061 | Loss: 0.9708\n",
      "Validation | Accuracy: 0.7513 | Loss: 0.8798\n",
      "\n",
      "Epoch 029 train | Accuracy: 0.7122 | Loss: 0.9604\n",
      "Validation | Accuracy: 0.7440 | Loss: 0.8801\n",
      "\n",
      "Epoch 030 train | Accuracy: 0.7097 | Loss: 0.9550\n",
      "Validation | Accuracy: 0.7563 | Loss: 1.0003\n",
      "\n",
      "Epoch 031 train | Accuracy: 0.7139 | Loss: 0.9758\n",
      "Validation | Accuracy: 0.7531 | Loss: 0.9140\n",
      "\n",
      "Epoch 032 train | Accuracy: 0.7067 | Loss: 0.9722\n",
      "Validation | Accuracy: 0.7637 | Loss: 0.8626\n",
      "\n",
      "Epoch 033 train | Accuracy: 0.7156 | Loss: 0.9586\n",
      "Validation | Accuracy: 0.7637 | Loss: 0.8758\n",
      "\n",
      "Epoch 034 train | Accuracy: 0.7400 | Loss: 0.8036\n",
      "Validation | Accuracy: 0.7818 | Loss: 0.6684\n",
      "\n",
      "Epoch 035 train | Accuracy: 0.7236 | Loss: 0.7616\n",
      "Validation | Accuracy: 0.7656 | Loss: 0.6470\n",
      "\n",
      "Epoch 036 train | Accuracy: 0.7291 | Loss: 0.7488\n",
      "Validation | Accuracy: 0.7575 | Loss: 0.6722\n",
      "\n",
      "Epoch 037 train | Accuracy: 0.7263 | Loss: 0.7521\n",
      "Validation | Accuracy: 0.7660 | Loss: 0.6747\n",
      "\n",
      "Epoch 038 train | Accuracy: 0.7295 | Loss: 0.7247\n",
      "Validation | Accuracy: 0.7785 | Loss: 0.6606\n",
      "\n",
      "Epoch 039 train | Accuracy: 0.7382 | Loss: 0.7299\n",
      "Validation | Accuracy: 0.7644 | Loss: 0.6917\n",
      "\n",
      "Epoch 040 train | Accuracy: 0.7396 | Loss: 0.7279\n",
      "Validation | Accuracy: 0.7660 | Loss: 0.6315\n",
      "\n",
      "Epoch 041 train | Accuracy: 0.7325 | Loss: 0.7315\n",
      "Validation | Accuracy: 0.7559 | Loss: 0.6761\n",
      "\n",
      "Epoch 042 train | Accuracy: 0.7321 | Loss: 0.7358\n",
      "Validation | Accuracy: 0.7396 | Loss: 0.7109\n",
      "\n",
      "Epoch 043 train | Accuracy: 0.7368 | Loss: 0.7290\n",
      "Validation | Accuracy: 0.7660 | Loss: 0.6499\n",
      "\n",
      "Epoch 044 train | Accuracy: 0.7380 | Loss: 0.7109\n",
      "Validation | Accuracy: 0.7532 | Loss: 0.6670\n",
      "\n",
      "Epoch 045 train | Accuracy: 0.7202 | Loss: 0.7453\n",
      "Validation | Accuracy: 0.7772 | Loss: 0.6693\n",
      "\n",
      "Epoch 046 train | Accuracy: 0.7254 | Loss: 0.7297\n",
      "Validation | Accuracy: 0.7695 | Loss: 0.6841\n",
      "\n",
      "Epoch 047 train | Accuracy: 0.7426 | Loss: 0.6843\n",
      "Validation | Accuracy: 0.7671 | Loss: 0.6631\n",
      "\n",
      "Epoch 048 train | Accuracy: 0.7558 | Loss: 0.6280\n",
      "Validation | Accuracy: 0.7940 | Loss: 0.5870\n",
      "\n",
      "Epoch 049 train | Accuracy: 0.7952 | Loss: 0.5270\n",
      "Validation | Accuracy: 0.8160 | Loss: 0.5373\n",
      "\n",
      "Epoch 050 train | Accuracy: 0.7888 | Loss: 0.5146\n",
      "Validation | Accuracy: 0.7991 | Loss: 0.5687\n",
      "\n",
      "Epoch 051 train | Accuracy: 0.7889 | Loss: 0.4979\n",
      "Validation | Accuracy: 0.8385 | Loss: 0.5402\n",
      "\n",
      "Epoch 052 train | Accuracy: 0.7949 | Loss: 0.4921\n",
      "Validation | Accuracy: 0.8165 | Loss: 0.5323\n",
      "\n",
      "Epoch 053 train | Accuracy: 0.8030 | Loss: 0.5061\n",
      "Validation | Accuracy: 0.8261 | Loss: 0.5269\n",
      "\n",
      "Epoch 054 train | Accuracy: 0.7964 | Loss: 0.4944\n",
      "Validation | Accuracy: 0.8080 | Loss: 0.5172\n",
      "\n",
      "Epoch 055 train | Accuracy: 0.8111 | Loss: 0.4711\n",
      "Validation | Accuracy: 0.7925 | Loss: 0.5837\n",
      "\n",
      "Epoch 056 train | Accuracy: 0.7933 | Loss: 0.4973\n",
      "Validation | Accuracy: 0.8129 | Loss: 0.5434\n",
      "\n",
      "Epoch 057 train | Accuracy: 0.7929 | Loss: 0.4881\n",
      "Validation | Accuracy: 0.8235 | Loss: 0.5137\n",
      "\n",
      "Epoch 058 train | Accuracy: 0.7911 | Loss: 0.5114\n",
      "Validation | Accuracy: 0.8156 | Loss: 0.5244\n",
      "\n",
      "Epoch 059 train | Accuracy: 0.7859 | Loss: 0.5567\n",
      "Validation | Accuracy: 0.7969 | Loss: 0.5607\n",
      "\n",
      "Epoch 060 train | Accuracy: 0.7789 | Loss: 0.5163\n",
      "Validation | Accuracy: 0.8122 | Loss: 0.5188\n",
      "\n",
      "Epoch 061 train | Accuracy: 0.8033 | Loss: 0.4811\n",
      "Validation | Accuracy: 0.8110 | Loss: 0.5580\n",
      "\n",
      "Epoch 062 train | Accuracy: 0.7868 | Loss: 0.5121\n",
      "Validation | Accuracy: 0.8303 | Loss: 0.5065\n",
      "\n",
      "Epoch 063 train | Accuracy: 0.8043 | Loss: 0.4958\n",
      "Validation | Accuracy: 0.8261 | Loss: 0.5020\n",
      "\n",
      "Epoch 064 train | Accuracy: 0.8136 | Loss: 0.4574\n",
      "Validation | Accuracy: 0.8207 | Loss: 0.5315\n",
      "\n",
      "Epoch 065 train | Accuracy: 0.8121 | Loss: 0.4612\n",
      "Validation | Accuracy: 0.8160 | Loss: 0.5572\n",
      "\n",
      "Epoch 066 train | Accuracy: 0.8076 | Loss: 0.4786\n",
      "Validation | Accuracy: 0.8515 | Loss: 0.4885\n",
      "\n",
      "Epoch 067 train | Accuracy: 0.8007 | Loss: 0.4980\n",
      "Validation | Accuracy: 0.8246 | Loss: 0.5288\n",
      "\n",
      "Epoch 068 train | Accuracy: 0.8081 | Loss: 0.4669\n",
      "Validation | Accuracy: 0.8292 | Loss: 0.5461\n",
      "\n",
      "Epoch 069 train | Accuracy: 0.7999 | Loss: 0.4852\n",
      "Validation | Accuracy: 0.8275 | Loss: 0.5215\n",
      "\n",
      "Epoch 070 train | Accuracy: 0.8099 | Loss: 0.4691\n",
      "Validation | Accuracy: 0.7779 | Loss: 0.5756\n",
      "\n",
      "Epoch 071 train | Accuracy: 0.8070 | Loss: 0.4655\n",
      "Validation | Accuracy: 0.8226 | Loss: 0.5599\n",
      "\n",
      "Epoch 072 train | Accuracy: 0.8094 | Loss: 0.4665\n",
      "Validation | Accuracy: 0.8308 | Loss: 0.5148\n",
      "\n",
      "Epoch 073 train | Accuracy: 0.8061 | Loss: 0.4894\n",
      "Validation | Accuracy: 0.7961 | Loss: 0.6434\n",
      "\n",
      "Epoch 074 train | Accuracy: 0.8058 | Loss: 0.4604\n",
      "Validation | Accuracy: 0.8341 | Loss: 0.5299\n",
      "\n",
      "Epoch 075 train | Accuracy: 0.8040 | Loss: 0.4874\n",
      "Validation | Accuracy: 0.7764 | Loss: 0.5851\n",
      "\n",
      "Epoch 076 train | Accuracy: 0.8002 | Loss: 0.5061\n",
      "Validation | Accuracy: 0.8515 | Loss: 0.5216\n",
      "\n",
      "Epoch 077 train | Accuracy: 0.8084 | Loss: 0.4674\n",
      "Validation | Accuracy: 0.8462 | Loss: 0.5192\n",
      "\n",
      "Epoch 078 train | Accuracy: 0.8112 | Loss: 0.4691\n",
      "Validation | Accuracy: 0.8449 | Loss: 0.5057\n",
      "\n",
      "Epoch 079 train | Accuracy: 0.7997 | Loss: 0.4954\n",
      "Validation | Accuracy: 0.8490 | Loss: 0.4774\n",
      "\n",
      "Epoch 080 train | Accuracy: 0.8097 | Loss: 0.4641\n",
      "Validation | Accuracy: 0.8383 | Loss: 0.4884\n",
      "\n",
      "Epoch 081 train | Accuracy: 0.8013 | Loss: 0.4886\n",
      "Validation | Accuracy: 0.8398 | Loss: 0.5008\n",
      "\n",
      "Epoch 082 train | Accuracy: 0.8162 | Loss: 0.4538\n",
      "Validation | Accuracy: 0.8374 | Loss: 0.4985\n",
      "\n",
      "Epoch 083 train | Accuracy: 0.8150 | Loss: 0.4662\n",
      "Validation | Accuracy: 0.8235 | Loss: 0.5109\n",
      "\n",
      "Epoch 084 train | Accuracy: 0.8168 | Loss: 0.4569\n",
      "Validation | Accuracy: 0.8152 | Loss: 0.5018\n",
      "\n",
      "Epoch 085 train | Accuracy: 0.8207 | Loss: 0.4506\n",
      "Validation | Accuracy: 0.8264 | Loss: 0.5095\n",
      "\n",
      "Epoch 086 train | Accuracy: 0.8152 | Loss: 0.4405\n",
      "Validation | Accuracy: 0.8321 | Loss: 0.5205\n",
      "\n",
      "Epoch 087 train | Accuracy: 0.8023 | Loss: 0.4770\n",
      "Validation | Accuracy: 0.8253 | Loss: 0.4998\n",
      "\n",
      "Epoch 088 train | Accuracy: 0.8056 | Loss: 0.4793\n",
      "Validation | Accuracy: 0.8325 | Loss: 0.5118\n",
      "\n",
      "Epoch 089 train | Accuracy: 0.8115 | Loss: 0.4669\n",
      "Validation | Accuracy: 0.8341 | Loss: 0.5404\n",
      "\n",
      "Epoch 090 train | Accuracy: 0.8112 | Loss: 0.4691\n",
      "Validation | Accuracy: 0.8217 | Loss: 0.4803\n",
      "\n",
      "Epoch 091 train | Accuracy: 0.7910 | Loss: 0.5084\n",
      "Validation | Accuracy: 0.8066 | Loss: 0.5410\n",
      "\n",
      "Epoch 092 train | Accuracy: 0.8039 | Loss: 0.4557\n",
      "Validation | Accuracy: 0.8233 | Loss: 0.4833\n",
      "\n",
      "Epoch 093 train | Accuracy: 0.8252 | Loss: 0.4347\n",
      "Validation | Accuracy: 0.8070 | Loss: 0.5120\n",
      "\n",
      "Epoch 094 train | Accuracy: 0.8258 | Loss: 0.4382\n",
      "Validation | Accuracy: 0.8191 | Loss: 0.4966\n",
      "\n",
      "Epoch 095 train | Accuracy: 0.8060 | Loss: 0.4583\n",
      "Validation | Accuracy: 0.8301 | Loss: 0.4990\n",
      "\n",
      "Epoch 096 train | Accuracy: 0.8153 | Loss: 0.4519\n",
      "Validation | Accuracy: 0.8019 | Loss: 0.5176\n",
      "\n",
      "Epoch 097 train | Accuracy: 0.8229 | Loss: 0.4509\n",
      "Validation | Accuracy: 0.8193 | Loss: 0.5418\n",
      "\n",
      "Epoch 098 train | Accuracy: 0.8149 | Loss: 0.4600\n",
      "Validation | Accuracy: 0.8099 | Loss: 0.4866\n",
      "\n",
      "Epoch 099 train | Accuracy: 0.8142 | Loss: 0.4493\n",
      "Validation | Accuracy: 0.8363 | Loss: 0.4676\n",
      "\n",
      "Epoch 100 train | Accuracy: 0.8199 | Loss: 0.4343\n",
      "Validation | Accuracy: 0.8352 | Loss: 0.4537\n",
      "\n",
      "Epoch 101 train | Accuracy: 0.8193 | Loss: 0.4554\n",
      "Validation | Accuracy: 0.8433 | Loss: 0.4547\n",
      "\n",
      "Epoch 102 train | Accuracy: 0.8118 | Loss: 0.4428\n",
      "Validation | Accuracy: 0.8209 | Loss: 0.4599\n",
      "\n",
      "Epoch 103 train | Accuracy: 0.8151 | Loss: 0.4580\n",
      "Validation | Accuracy: 0.8125 | Loss: 0.5437\n",
      "\n",
      "Epoch 104 train | Accuracy: 0.8183 | Loss: 0.4504\n",
      "Validation | Accuracy: 0.8286 | Loss: 0.5081\n",
      "\n",
      "Epoch 105 train | Accuracy: 0.8212 | Loss: 0.4355\n",
      "Validation | Accuracy: 0.8290 | Loss: 0.4858\n",
      "\n",
      "Epoch 106 train | Accuracy: 0.8092 | Loss: 0.4422\n",
      "Validation | Accuracy: 0.8254 | Loss: 0.5441\n",
      "\n",
      "Epoch 107 train | Accuracy: 0.8204 | Loss: 0.4480\n",
      "Validation | Accuracy: 0.8099 | Loss: 0.5122\n",
      "\n",
      "Epoch 108 train | Accuracy: 0.8099 | Loss: 0.4504\n",
      "Validation | Accuracy: 0.8028 | Loss: 0.4674\n",
      "\n",
      "Epoch 109 train | Accuracy: 0.8306 | Loss: 0.4257\n",
      "Validation | Accuracy: 0.8421 | Loss: 0.4792\n",
      "\n",
      "Epoch 110 train | Accuracy: 0.8188 | Loss: 0.4490\n",
      "Validation | Accuracy: 0.8506 | Loss: 0.4727\n",
      "\n",
      "Epoch 111 train | Accuracy: 0.8196 | Loss: 0.4293\n",
      "Validation | Accuracy: 0.8348 | Loss: 0.5008\n",
      "\n",
      "Epoch 112 train | Accuracy: 0.8192 | Loss: 0.4438\n",
      "Validation | Accuracy: 0.8438 | Loss: 0.5139\n",
      "\n",
      "Epoch 113 train | Accuracy: 0.8191 | Loss: 0.4467\n",
      "Validation | Accuracy: 0.8196 | Loss: 0.5168\n",
      "\n",
      "Epoch 114 train | Accuracy: 0.8142 | Loss: 0.4659\n",
      "Validation | Accuracy: 0.8099 | Loss: 0.5942\n",
      "\n",
      "Epoch 115 train | Accuracy: 0.8018 | Loss: 0.5197\n",
      "Validation | Accuracy: 0.8212 | Loss: 0.5627\n",
      "\n",
      "Epoch 116 train | Accuracy: 0.8124 | Loss: 0.4615\n",
      "Validation | Accuracy: 0.8240 | Loss: 0.5261\n",
      "\n",
      "Epoch 117 train | Accuracy: 0.8304 | Loss: 0.4278\n",
      "Validation | Accuracy: 0.8471 | Loss: 0.4819\n",
      "\n",
      "Epoch 118 train | Accuracy: 0.8132 | Loss: 0.4222\n",
      "Validation | Accuracy: 0.8654 | Loss: 0.4488\n",
      "\n",
      "Epoch 119 train | Accuracy: 0.8155 | Loss: 0.4442\n",
      "Validation | Accuracy: 0.8502 | Loss: 0.4819\n",
      "\n",
      "Epoch 120 train | Accuracy: 0.8265 | Loss: 0.4256\n",
      "Validation | Accuracy: 0.8398 | Loss: 0.5046\n",
      "\n",
      "Epoch 121 train | Accuracy: 0.8157 | Loss: 0.4365\n",
      "Validation | Accuracy: 0.8230 | Loss: 0.4523\n",
      "\n",
      "Epoch 122 train | Accuracy: 0.8277 | Loss: 0.4147\n",
      "Validation | Accuracy: 0.8178 | Loss: 0.5228\n",
      "\n",
      "Epoch 123 train | Accuracy: 0.8142 | Loss: 0.4558\n",
      "Validation | Accuracy: 0.8303 | Loss: 0.4890\n",
      "\n",
      "Epoch 124 train | Accuracy: 0.8269 | Loss: 0.4221\n",
      "Validation | Accuracy: 0.8321 | Loss: 0.4943\n",
      "\n",
      "Epoch 125 train | Accuracy: 0.8202 | Loss: 0.4452\n",
      "Validation | Accuracy: 0.8271 | Loss: 0.5191\n",
      "\n",
      "Epoch 126 train | Accuracy: 0.8301 | Loss: 0.4146\n",
      "Validation | Accuracy: 0.8418 | Loss: 0.4629\n",
      "\n",
      "Epoch 127 train | Accuracy: 0.8218 | Loss: 0.4317\n",
      "Validation | Accuracy: 0.8315 | Loss: 0.4728\n",
      "\n",
      "Epoch 128 train | Accuracy: 0.8304 | Loss: 0.4313\n",
      "Validation | Accuracy: 0.8492 | Loss: 0.4740\n",
      "\n",
      "Epoch 129 train | Accuracy: 0.8275 | Loss: 0.4461\n",
      "Validation | Accuracy: 0.8282 | Loss: 0.5227\n",
      "\n",
      "Epoch 130 train | Accuracy: 0.8245 | Loss: 0.4321\n",
      "Validation | Accuracy: 0.8204 | Loss: 0.4933\n",
      "\n",
      "Epoch 131 train | Accuracy: 0.8321 | Loss: 0.4165\n",
      "Validation | Accuracy: 0.8488 | Loss: 0.4675\n",
      "\n",
      "Epoch 132 train | Accuracy: 0.8287 | Loss: 0.4367\n",
      "Validation | Accuracy: 0.8464 | Loss: 0.4914\n",
      "\n",
      "Epoch 133 train | Accuracy: 0.8187 | Loss: 0.4377\n",
      "Validation | Accuracy: 0.8426 | Loss: 0.4860\n",
      "\n",
      "Epoch 134 train | Accuracy: 0.8244 | Loss: 0.4182\n",
      "Validation | Accuracy: 0.8442 | Loss: 0.5058\n",
      "\n",
      "Epoch 135 train | Accuracy: 0.8122 | Loss: 0.4466\n",
      "Validation | Accuracy: 0.8152 | Loss: 0.5541\n",
      "\n",
      "Epoch 136 train | Accuracy: 0.8088 | Loss: 0.4527\n",
      "Validation | Accuracy: 0.8456 | Loss: 0.4604\n",
      "\n",
      "Epoch 137 train | Accuracy: 0.8147 | Loss: 0.4472\n",
      "Validation | Accuracy: 0.8541 | Loss: 0.4809\n",
      "\n",
      "Epoch 138 train | Accuracy: 0.8319 | Loss: 0.4033\n",
      "Validation | Accuracy: 0.8445 | Loss: 0.5223\n",
      "\n",
      "Epoch 139 train | Accuracy: 0.8319 | Loss: 0.4307\n",
      "Validation | Accuracy: 0.8499 | Loss: 0.4868\n",
      "\n",
      "Epoch 140 train | Accuracy: 0.8324 | Loss: 0.4121\n",
      "Validation | Accuracy: 0.8000 | Loss: 0.5511\n",
      "\n",
      "Epoch 141 train | Accuracy: 0.8203 | Loss: 0.4265\n",
      "Validation | Accuracy: 0.8106 | Loss: 0.5179\n",
      "\n",
      "Epoch 142 train | Accuracy: 0.8287 | Loss: 0.4160\n",
      "Validation | Accuracy: 0.8530 | Loss: 0.4740\n",
      "\n",
      "Epoch 143 train | Accuracy: 0.8273 | Loss: 0.4274\n",
      "Validation | Accuracy: 0.8372 | Loss: 0.4843\n",
      "\n",
      "Epoch 144 train | Accuracy: 0.8260 | Loss: 0.4216\n",
      "Validation | Accuracy: 0.8480 | Loss: 0.4679\n",
      "\n",
      "Epoch 145 train | Accuracy: 0.8239 | Loss: 0.4139\n",
      "Validation | Accuracy: 0.7969 | Loss: 0.6099\n",
      "\n",
      "Epoch 146 train | Accuracy: 0.8160 | Loss: 0.4398\n",
      "Validation | Accuracy: 0.8350 | Loss: 0.5187\n",
      "\n",
      "Epoch 147 train | Accuracy: 0.8282 | Loss: 0.4429\n",
      "Validation | Accuracy: 0.8349 | Loss: 0.4710\n",
      "\n",
      "Epoch 148 train | Accuracy: 0.8366 | Loss: 0.4240\n",
      "Validation | Accuracy: 0.8407 | Loss: 0.5280\n",
      "\n",
      "Epoch 149 train | Accuracy: 0.8187 | Loss: 0.4306\n",
      "Validation | Accuracy: 0.8271 | Loss: 0.5176\n",
      "\n",
      "Epoch 150 train | Accuracy: 0.8245 | Loss: 0.4090\n",
      "Validation | Accuracy: 0.8310 | Loss: 0.4565\n",
      "\n",
      "Epoch 151 train | Accuracy: 0.8361 | Loss: 0.4129\n",
      "Validation | Accuracy: 0.8314 | Loss: 0.4877\n",
      "\n",
      "Epoch 152 train | Accuracy: 0.8428 | Loss: 0.3845\n",
      "Validation | Accuracy: 0.8282 | Loss: 0.6289\n",
      "\n",
      "Epoch 153 train | Accuracy: 0.8210 | Loss: 0.4130\n",
      "Validation | Accuracy: 0.8213 | Loss: 0.5477\n",
      "\n",
      "Epoch 154 train | Accuracy: 0.8302 | Loss: 0.4110\n",
      "Validation | Accuracy: 0.8179 | Loss: 0.5131\n",
      "\n",
      "Epoch 155 train | Accuracy: 0.8318 | Loss: 0.4209\n",
      "Validation | Accuracy: 0.8336 | Loss: 0.5208\n",
      "\n",
      "Epoch 156 train | Accuracy: 0.8280 | Loss: 0.4075\n",
      "Validation | Accuracy: 0.8282 | Loss: 0.5835\n",
      "\n",
      "Epoch 157 train | Accuracy: 0.8234 | Loss: 0.4249\n",
      "Validation | Accuracy: 0.8301 | Loss: 0.4964\n",
      "\n",
      "Epoch 158 train | Accuracy: 0.8221 | Loss: 0.4098\n",
      "Validation | Accuracy: 0.8171 | Loss: 0.5177\n",
      "\n",
      "Epoch 159 train | Accuracy: 0.8337 | Loss: 0.4050\n",
      "Validation | Accuracy: 0.8217 | Loss: 0.5299\n",
      "\n",
      "Epoch 160 train | Accuracy: 0.8320 | Loss: 0.3948\n",
      "Validation | Accuracy: 0.8034 | Loss: 0.5483\n",
      "\n",
      "Epoch 161 train | Accuracy: 0.8259 | Loss: 0.4206\n",
      "Validation | Accuracy: 0.8101 | Loss: 0.5308\n",
      "\n",
      "Epoch 162 train | Accuracy: 0.8266 | Loss: 0.4124\n",
      "Validation | Accuracy: 0.8119 | Loss: 0.5668\n",
      "\n",
      "Epoch 163 train | Accuracy: 0.8329 | Loss: 0.4265\n",
      "Validation | Accuracy: 0.8050 | Loss: 0.5457\n",
      "\n",
      "Epoch 164 train | Accuracy: 0.8222 | Loss: 0.4222\n",
      "Validation | Accuracy: 0.8147 | Loss: 0.5590\n",
      "\n",
      "Epoch 165 train | Accuracy: 0.8284 | Loss: 0.4057\n",
      "Validation | Accuracy: 0.8212 | Loss: 0.5220\n",
      "\n",
      "Epoch 166 train | Accuracy: 0.8336 | Loss: 0.4089\n",
      "Validation | Accuracy: 0.8123 | Loss: 0.5905\n",
      "\n",
      "Epoch 167 train | Accuracy: 0.8276 | Loss: 0.4125\n",
      "Validation | Accuracy: 0.8314 | Loss: 0.5342\n",
      "\n",
      "Epoch 168 train | Accuracy: 0.8386 | Loss: 0.4022\n",
      "Validation | Accuracy: 0.7993 | Loss: 0.5722\n",
      "\n",
      "Epoch 169 train | Accuracy: 0.8199 | Loss: 0.4368\n",
      "Validation | Accuracy: 0.7737 | Loss: 0.5683\n",
      "\n",
      "Epoch 170 train | Accuracy: 0.8254 | Loss: 0.4159\n",
      "Validation | Accuracy: 0.8010 | Loss: 0.5215\n",
      "\n",
      "Epoch 171 train | Accuracy: 0.8174 | Loss: 0.4304\n",
      "Validation | Accuracy: 0.8230 | Loss: 0.4990\n",
      "\n",
      "Epoch 172 train | Accuracy: 0.8334 | Loss: 0.3965\n",
      "Validation | Accuracy: 0.8096 | Loss: 0.5055\n",
      "\n",
      "Epoch 173 train | Accuracy: 0.8192 | Loss: 0.4260\n",
      "Validation | Accuracy: 0.7982 | Loss: 0.5523\n",
      "\n",
      "Epoch 174 train | Accuracy: 0.8394 | Loss: 0.3984\n",
      "Validation | Accuracy: 0.8221 | Loss: 0.5493\n",
      "\n",
      "Epoch 175 train | Accuracy: 0.8224 | Loss: 0.4162\n",
      "Validation | Accuracy: 0.8325 | Loss: 0.5477\n",
      "\n",
      "Epoch 176 train | Accuracy: 0.8464 | Loss: 0.3886\n",
      "Validation | Accuracy: 0.8198 | Loss: 0.4955\n",
      "\n",
      "Epoch 177 train | Accuracy: 0.8335 | Loss: 0.4129\n",
      "Validation | Accuracy: 0.8016 | Loss: 0.6229\n",
      "\n",
      "Epoch 178 train | Accuracy: 0.8266 | Loss: 0.4312\n",
      "Validation | Accuracy: 0.7843 | Loss: 0.5803\n",
      "\n",
      "Epoch 179 train | Accuracy: 0.8345 | Loss: 0.4151\n",
      "Validation | Accuracy: 0.8341 | Loss: 0.4561\n",
      "\n",
      "Epoch 180 train | Accuracy: 0.8258 | Loss: 0.4274\n",
      "Validation | Accuracy: 0.8115 | Loss: 0.6246\n",
      "\n",
      "Epoch 181 train | Accuracy: 0.8120 | Loss: 0.4451\n",
      "Validation | Accuracy: 0.8209 | Loss: 0.5661\n",
      "\n",
      "Epoch 182 train | Accuracy: 0.8430 | Loss: 0.3981\n",
      "Validation | Accuracy: 0.7984 | Loss: 0.5292\n",
      "\n",
      "Epoch 183 train | Accuracy: 0.8233 | Loss: 0.4093\n",
      "Validation | Accuracy: 0.7516 | Loss: 0.5966\n",
      "\n",
      "Epoch 184 train | Accuracy: 0.8280 | Loss: 0.4203\n",
      "Validation | Accuracy: 0.8055 | Loss: 0.5800\n",
      "\n",
      "Epoch 185 train | Accuracy: 0.8271 | Loss: 0.4399\n",
      "Validation | Accuracy: 0.7920 | Loss: 0.5809\n",
      "\n",
      "Epoch 186 train | Accuracy: 0.8366 | Loss: 0.4079\n",
      "Validation | Accuracy: 0.7867 | Loss: 0.5190\n",
      "\n",
      "Epoch 187 train | Accuracy: 0.8230 | Loss: 0.4540\n",
      "Validation | Accuracy: 0.8268 | Loss: 0.4903\n",
      "\n",
      "Epoch 188 train | Accuracy: 0.8364 | Loss: 0.4072\n",
      "Validation | Accuracy: 0.7905 | Loss: 0.5433\n",
      "\n",
      "Epoch 189 train | Accuracy: 0.8409 | Loss: 0.3807\n",
      "Validation | Accuracy: 0.8181 | Loss: 0.5228\n",
      "\n",
      "Epoch 190 train | Accuracy: 0.8407 | Loss: 0.4064\n",
      "Validation | Accuracy: 0.7826 | Loss: 0.5520\n",
      "\n",
      "Epoch 191 train | Accuracy: 0.8243 | Loss: 0.4237\n",
      "Validation | Accuracy: 0.8292 | Loss: 0.5378\n",
      "\n",
      "Epoch 192 train | Accuracy: 0.8455 | Loss: 0.3978\n",
      "Validation | Accuracy: 0.8290 | Loss: 0.5414\n",
      "\n",
      "Epoch 193 train | Accuracy: 0.8393 | Loss: 0.4174\n",
      "Validation | Accuracy: 0.8200 | Loss: 0.5017\n",
      "\n",
      "Epoch 194 train | Accuracy: 0.8283 | Loss: 0.4090\n",
      "Validation | Accuracy: 0.8306 | Loss: 0.4988\n",
      "\n",
      "Epoch 195 train | Accuracy: 0.8308 | Loss: 0.4160\n",
      "Validation | Accuracy: 0.8188 | Loss: 0.4809\n",
      "\n",
      "Epoch 196 train | Accuracy: 0.8334 | Loss: 0.4216\n",
      "Validation | Accuracy: 0.8325 | Loss: 0.5507\n",
      "\n",
      "Epoch 197 train | Accuracy: 0.8348 | Loss: 0.4000\n",
      "Validation | Accuracy: 0.7998 | Loss: 0.6347\n",
      "\n",
      "Epoch 198 train | Accuracy: 0.8315 | Loss: 0.4025\n",
      "Validation | Accuracy: 0.8514 | Loss: 0.5078\n",
      "\n",
      "Epoch 199 train | Accuracy: 0.8325 | Loss: 0.4093\n",
      "Validation | Accuracy: 0.8312 | Loss: 0.4781\n",
      "\n",
      "Epoch 200 train | Accuracy: 0.8484 | Loss: 0.3748\n",
      "Validation | Accuracy: 0.8362 | Loss: 0.4827\n",
      "\n",
      "Finish training! Using 391.5677 s:\n"
     ]
    }
   ],
   "source": [
    "train_acc_all, train_loss_all  = [], []\n",
    "val_acc_all, val_loss_all = [], []\n",
    "\n",
    "\n",
    "train_startime = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    #### train one epoch \n",
    "    model.train()\n",
    "\n",
    "    train_acc_list = []\n",
    "    train_loss_list = []\n",
    "\n",
    "    # feed graph to algorithm one by one\n",
    "    for batch, subgraph in enumerate(train_dataloader):\n",
    "\n",
    "        subgraph = subgraph.to(device) \n",
    "        nfeat = subgraph.ndata['feat'].float()\n",
    "        efeat = subgraph.edata['relation'].float()\n",
    "\n",
    "        logits = model(subgraph, nfeat, efeat) # get the prediction from models \n",
    "\n",
    "        # calculate the accuracy \n",
    "        gt = torch.argmax(subgraph.ndata['label'], dim=1) # ground true labels\n",
    "        pre  = torch.argmax(logits, dim=1)  # prediction labels \n",
    "        correct = torch.sum(pre == gt) # calculate the right labels \n",
    "\n",
    "        acc = correct.item()*1.0/len(gt) # calculate the accuracy \n",
    "        train_acc_list.append(acc) \n",
    "\n",
    "        # compute the loss\n",
    "        loss = F.cross_entropy(logits, gt) # using cross entropy \n",
    "        train_loss_list.append(loss.item()) \n",
    "\n",
    "        # backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # calculate acc and loss for each epoch\n",
    "    train_loss_epoch =  np.array(train_loss_list).mean()\n",
    "    train_acc_epoch =  np.array(train_acc_list).mean()\n",
    "\n",
    "    train_loss_all.append(train_loss_epoch)\n",
    "    train_acc_all.append(train_acc_epoch)\n",
    "\n",
    "    print(\"Epoch {:03d} train | Accuracy: {:.4f} | Loss: {:.4f}\".format(\\\n",
    "        epoch+1, train_acc_epoch, train_loss_epoch))\n",
    "\n",
    "\n",
    "    #### start evaluation\n",
    "    val_acc_list, val_loss_list = [], []\n",
    "\n",
    "    for batch, subgraph in enumerate(valid_dataloader):\n",
    "        subgraph = subgraph.to(device)\n",
    "\n",
    "        # calculate the accuracy and loss\n",
    "        nfeat = subgraph.ndata['feat'].float()\n",
    "        efeat = subgraph.edata['relation'].float()\n",
    "\n",
    "        acc, loss, _, _, _, _ = evalEdge(model, nfeat, efeat, subgraph, subgraph.ndata['label'], n_classes)\n",
    "\n",
    "        # obtain acc and loss\n",
    "        val_acc_list.append(acc)\n",
    "        val_loss_list.append(loss.item())\n",
    "\n",
    "    # calculate the loss and acc for all graphs in one epoch\n",
    "    val_loss_epoch =  np.array(val_loss_list).mean()\n",
    "    val_acc_epoch =  np.array(val_acc_list).mean()\n",
    "\n",
    "    # append for drawing the curs\n",
    "    val_acc_all.append(val_acc_epoch)\n",
    "    val_loss_all.append(val_loss_epoch)\n",
    "        \n",
    "    print(\"Validation | Accuracy: {:.4f} | Loss: {:.4f}\\n\".format(val_acc_epoch, val_loss_epoch))\n",
    "\n",
    "    ############ save the best acc epoch ############\n",
    "    if val_acc_epoch >= max(val_acc_all):\n",
    "        torch.save(model, \"best_user.pt\")\n",
    "    \n",
    "train_endtime = time.time()\n",
    "\n",
    "print(\"Finish training! Using {:.4f} s:\".format(train_endtime - train_startime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start to test \n",
    "\n",
    "We prepare our best weight file here. (named as \"best.pt\")\n",
    "The test accuracy based on our weight file is around 80%. \n",
    "\n",
    "You can also set your criterion to select your best weight, and test here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load user best weight\n",
      "Test Accuracy: 0.7970\n",
      "F1 score: 0.780126\n",
      "Test time: 0.2603 s\n",
      "Confusion matrix:\n",
      "[[35  0  9  0  0  0  0  0  1]\n",
      " [ 1 44  0  0  0  0  0  0  0]\n",
      " [10  0 34  0  0  0  0  0  0]\n",
      " [ 0  0  0 72  6  3  0  0  0]\n",
      " [ 0  0  0  3 27  2  0  0  0]\n",
      " [ 1  0  0 17  0 46  3  0  3]\n",
      " [ 0  0  0  2  0 17  8  0  0]\n",
      " [ 0  0  0  0  0  0  0 41  0]\n",
      " [ 0  0  0  4  0  4  0  0 22]]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"best_user.pt\"):\n",
    "    filename = \"best_default.pt\"\n",
    "    print(\"Load default best weight\")\n",
    "else:\n",
    "    filename=\"best_user.pt\"\n",
    "    print(\"Load user best weight\")\n",
    "\n",
    "\n",
    "model = torch.load(filename)  # read the best weight\n",
    "model.eval()    \n",
    "\n",
    "# print(model)\n",
    "\n",
    "test_acc_list = [] # list for storing the acc from each graph\n",
    "pre, gt = [], []\n",
    "\n",
    "\n",
    "test_startime = time.time()\n",
    "\n",
    "for batch, subgraph in enumerate(test_dataloader):\n",
    "    subgraph = subgraph.to(device)\n",
    "    # subgraph = dgl.add_self_loop(subgraph)\n",
    "\n",
    "    nfeat = subgraph.ndata['feat'].float()\n",
    "    efeat = subgraph.edata['relation'].float()\n",
    "\n",
    "    acc, _, _, _, one_pre, one_gt = evalEdge(model, nfeat, efeat, \\\n",
    "        subgraph, subgraph.ndata['label'], n_classes)\n",
    "\n",
    "    test_acc_list.append(acc)\n",
    "    pre.extend(one_pre)\n",
    "    gt.extend(one_gt)\n",
    "\n",
    "\n",
    "\n",
    "test_time = time.time() - test_startime\n",
    "\n",
    "test_acc = np.array(test_acc_list).mean()\n",
    "\n",
    "cm = confusion_matrix(gt, pre)  # confusion matrix, default function from scikit-learn\n",
    "\n",
    "f1 = f1_score(gt, pre, average='macro') # f1, default function from scikit-learn\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(test_acc))\n",
    "\n",
    "print(\"F1 score: {:4f}\".format(f1))\n",
    "\n",
    "print(\"Test time: {:.4f} s\".format(test_time))\n",
    "\n",
    "print(f\"Confusion matrix:\\n{cm}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f7df54c7b13a7ddac48d89097bf9b5f3d407805e73bd908f10313d9de5254a8"
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('gnn': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
